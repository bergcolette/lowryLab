#!/bin/bash --login
# Job name:
#SBATCH --job-name=get_position_list_allbcfs
#
# Number of nodes
#SBATCH --nodes=1
#
# Number of tasks to run on each node
#SBATCH --ntasks-per-node=16
#
#
# Wall time (e.g. "minutes", "hours:minutes:seconds", "days-hours", "days-hours:minutes"):
#SBATCH --time=40:00:00
#
# Mail type:
#SBATCH --mail-type=ALL
#
# Mail user:
#SBATCH --mail-user=bergcole@msu.edu
#
# Standard out and error:
#SBATCH --output=%x-%j.SLURMout
# 
# indicate that I'm using an array
#SBATCH --array=1-18


echo "JobID: $SLURM_JOB_ID"
echo "Running on node: `hostname`"


module purge 
module load   GCC/12.2.0 BCFtools/1.17

# script for filtering bcf files from the switchgrass diversity panel
# these genotype files were initially processed by Paulo 

# setting directory where bcfs are stored & where the filtered genotype files will go
bcfDir="/mnt/research/glbrc_group/lowry_lab/WGS/genotyping_pi/population_L/chr_level/"
outDir="/mnt/scratch/bergcole/filtered_switchgrass_genotypes"

# call to the chromosome array
sampleID=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' chromosomes.array)

# get list of positions from every vcf @ every filtering level 

bcftools query -f '%CHROM %POS\n' ${outDir}/${sampleID}_snps.bcf > ${sampleID}_90_pos.txt

bcftools query -f '%CHROM %POS\n' ${outDir}/${sampleID}_100_snps.bcf > ${sampleID}_100_pos.txt

bcftools query -f '%CHROM %POS\n' ${outDir}/${sampleID}_99_snps.bcf > ${sampleID}_99_pos.txt

bcftools query -f '%CHROM %POS\n' ${outDir}/${sampleID}_97.5_snps.bcf > ${sampleID}_97.5_pos.txt

bcftools query -f '%CHROM %POS\n' ${outDir}/${sampleID}_95_snps.bcf > ${sampleID}_95_pos.txt

# concatenate all chromosomes with the same filtering level 
cat *90_pos.txt > positions_90_filt.txt
cat *100_pos.txt > positions_100_filt.txt
cat *99_pos.txt > positions_99_filt.txt
cat *97.5_pos.txt > positions_97.5_filt.txt
cat *95_pos.txt > positions_95_filt.txt